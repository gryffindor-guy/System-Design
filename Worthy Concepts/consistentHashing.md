# [Consistent Hashing] (https://www.educative.io/courses/grokking-the-system-design-interview/B81vnyp0GpY)

### Background

While designing a scalable system, the most important aspect is defining how the data will be partitioned and replicated across servers. Letâ€™s first define these terms before moving on:

Data partitioning: It is the process of distributing data across a set of servers. It improves the scalability and performance of the system.

Data replication: It is the process of making multiple copies of data and storing them on different servers. It improves the availability and durability of the data across the system.

Data partition and replication strategies lie at the core of any distributed system. A carefully designed scheme for partitioning and replicating the data enhances the performance, availability, and reliability of the system and also defines how efficiently the system will be scaled and managed.

David Karger et al. first introduced Consistent Hashing in their 1997 paper and suggested its use in distributed caching. Later, Consistent Hashing was adopted and enhanced to be used across many distributed systems. In this lesson we will see how Consistent Hashing efficiently solves the problem of data partitioning and replication.

### What is data partitioning?



### Consistent Hashing to the rescue

### Virtual nodes
 - Advantages of Vnodes

### Data replication using Consistent Hashing

### Consistent Hashing in System Design Interviews

### Consistent Hashing use cases